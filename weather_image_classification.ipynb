{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9551dc-cdbb-473f-b722-20ab92b10d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119cca14-6d3e-42ed-b4e6-8a9eaede8a73",
   "metadata": {},
   "source": [
    "Using Sagemaker SDK get your AWS account region, execution role and the default S3 bucket. Push the training and validation set along with the metadata files into this default S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc70091-49ed-4b16-baaf-ade748f1d043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-us-east-1-619836274583\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::619836274583:role/service-role/AmazonSageMaker-ExecutionRole-20230220T203798\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket= session.default_bucket()\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd0455-486f-4056-9636-b0307c20a913",
   "metadata": {},
   "source": [
    "In AWS SageMaker, you can take advantage of prebuilt Docker images that support deep learning frameworks and other dependencies required for training and inference. We can leverage the Sagemaker Python SDK to utilize the latest machine learning or deep learning models. In the below code I have used the image_uris function to retrieve the latest image-classification image. The model artifacts would be stored in the location specified in the S3 path. Learn more about the pre built models here https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e7f1e4-b6ed-4ed9-8ace-851d90d50807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "# Use the image_uris function to retrieve the latest 'image-classification' image \n",
    "image_classification_model_image = sagemaker.image_uris.retrieve('image-classification',region,version='latest')\n",
    "s3_path = f\"s3://{bucket}/weather_classification_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998768a5-887b-450c-9ae2-e18eae18ec49",
   "metadata": {},
   "source": [
    "Use the Sagemaker estimator to run the training job. This function requires the current Sagemaker execution role and session variables along with the other necessary parameters. There is a parameter called instance _count and it is set to 1. If you have millions of images for training, then you can increase the instance count proportionately and Sagemaker would distribute the training load across all the instances, and we donâ€™t have to manage these instances.  You can find more about Sagemaker estimator here at https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-adapt-your-own-private-registry-estimator.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d1f8b1-3e5c-4160-95b3-b1c2e100078c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_classification_model = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_classification_model_image,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    volume_size=50,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    role=role,\n",
    "    output_path=s3_path,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6202e4e-de88-4136-b05b-9eb4a494f8ed",
   "metadata": {},
   "source": [
    "We have the option of tuning the hyperparameters for our image classification model. Here two important parameters to be noted is use_pretrained_model=1 and multi_label=1. The latter indicates multi image classification while the former helps us with transfer learning because we want to make predictions on a custom dataset. We take a pre trained model, remove the final layers and retrain with our custom images. Additionally, I have set the image shape, number of classes, total number of training samples, etc,. There are several hyperparameters that can be tuned. Find them out here https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html. Also make sure that the image shape is 224 x 224 x 3 because earlier I used 300 x 300 x 3 and this caused problems during model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c762126-cdd5-4a3a-aed3-24dc25fa5151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_classification_model.set_hyperparameters(\n",
    "    image_shape='3,224,224' ,\n",
    "    num_classes=4, \n",
    "    num_layers=18,\n",
    "    num_training_samples=894,\n",
    "    use_pretrained_model=1,\n",
    "    multi_label=1,\n",
    "    learning_rate=0.001,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a8505-32c3-459c-b3e1-1845fb9e8c40",
   "metadata": {},
   "source": [
    "AWS offers several image formats for training models, including the one used in this project. To learn more about this method and other available options, please refer to the documentation at https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html. When training the model, it's important to specify four channels for the InputDataConfig parameter: train, validation, train_lst, and validation_lst. These channel names should not be changed. Additionally, the content type for all four channels should be set to application/x-image. To properly point to your image data, you can specify the main S3 path to the images in the s3_data parameter of the training input. The relative path or file name for each image should be included in the metadata file (lst file). This file should have three columns: the index of the image within the folder, the label of the image, and the relative path of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93508071-b26a-41aa-9047-801d1f984914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.session import TrainingInput\n",
    "model_inputs = {\n",
    "        \"train\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/weather_classification/train/\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"validation\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/weather_classification/validation/\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"train_lst\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/weather_classification/train.lst\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"validation_lst\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/weather_classification/validation.lst\",\n",
    "            content_type=\"application/x-image\"\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0992d5d9-ba4e-45d9-aae8-e505b023a32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: image-classification-2023-03-14-17-35-38-045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-14 17:35:38 Starting - Starting the training job...\n",
      "2023-03-14 17:36:07 Starting - Preparing the instances for training.........\n",
      "2023-03-14 17:37:19 Downloading - Downloading input data...\n",
      "2023-03-14 17:37:53 Training - Downloading the training image............\n",
      "2023-03-14 17:39:49 Training - Training image download completed. Training in progress....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mNvidia gpu devices, drivers and cuda toolkit versions (only available on hosts with GPU):\u001b[0m\n",
      "\u001b[34mTue Mar 14 17:40:30 2023       \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\u001b[0m\n",
      "\u001b[34m|-------------------------------+----------------------+----------------------+\u001b[0m\n",
      "\u001b[34m| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\u001b[0m\n",
      "\u001b[34m| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\u001b[0m\n",
      "\u001b[34m|                               |                      |               MIG M. |\u001b[0m\n",
      "\u001b[34m|===============================+======================+======================|\u001b[0m\n",
      "\u001b[34m|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\u001b[0m\n",
      "\u001b[34m| N/A   30C    P8    24W / 149W |      0MiB / 11441MiB |      0%      Default |\u001b[0m\n",
      "\u001b[34m|                               |                      |                  N/A |\u001b[0m\n",
      "\u001b[34m+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| Processes:                                                                  |\u001b[0m\n",
      "\u001b[34m|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\u001b[0m\n",
      "\u001b[34m|        ID   ID                                                   Usage      |\u001b[0m\n",
      "\u001b[34m|=============================================================================|\u001b[0m\n",
      "\u001b[34m|  No running processes found                                                 |\u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34mChecking for nvidia driver and cuda compatibility.\u001b[0m\n",
      "\u001b[34mCUDA Compatibility driver provided.\u001b[0m\n",
      "\u001b[34mProceeding with compatibility check between driver, cuda-toolkit and cuda-compat.\u001b[0m\n",
      "\u001b[34mDetected cuda-toolkit version: 11.1.\u001b[0m\n",
      "\u001b[34mDetected cuda-compat version: 455.32.00.\u001b[0m\n",
      "\u001b[34mDetected Nvidia driver version: 470.57.02.\u001b[0m\n",
      "\u001b[34mNvidia driver compatible with cuda-toolkit. Disabling cuda-compat.\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:34 INFO 139784435615552] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/image_classification/default-input.json: {'use_pretrained_model': 0, 'num_layers': 152, 'epochs': 30, 'learning_rate': 0.1, 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': 32, 'image_shape': '3,224,224', 'precision_dtype': 'float32'}\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:34 INFO 139784435615552] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '5', 'image_shape': '3,224,224', 'learning_rate': '0.001', 'multi_label': '1', 'num_classes': '4', 'num_layers': '18', 'num_training_samples': '894', 'use_pretrained_model': '1'}\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:34 INFO 139784435615552] Final configuration: {'use_pretrained_model': '1', 'num_layers': '18', 'epochs': '5', 'learning_rate': '0.001', 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': 32, 'image_shape': '3,224,224', 'precision_dtype': 'float32', 'multi_label': '1', 'num_classes': '4', 'num_training_samples': '894'}\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:34 INFO 139784435615552] Searching for .lst files in /opt/ml/input/data/train_lst.\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:34 INFO 139784435615552] Creating record files for train.lst\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] Done creating record files...\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] Searching for .lst files in /opt/ml/input/data/validation_lst.\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] Creating record files for validation.lst\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] Done creating record files...\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] label-format is multi-hot\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] multi_label: 1\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] num_layers: 18\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] data type: <class 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] epochs: 5\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] learning_rate: 0.001\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] num_training_samples: 894\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] mini_batch_size: 32\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] num_classes: 4\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] kv_store: device\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] --------------------\u001b[0m\n",
      "\u001b[34m[17:40:35] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.38.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[17:40:35] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.38.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:35 INFO 139784435615552] Setting number of threads: 3\u001b[0m\n",
      "\u001b[34m[17:40:41] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.38.0/AL2_x86_64/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:48 INFO 139784435615552] Epoch[0] Batch [20]#011Speed: 87.648 samples/sec#011accuracy=0.718750\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:49 INFO 139784435615552] Epoch[0] Train-accuracy=0.722222\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:49 INFO 139784435615552] Epoch[0] Time cost=8.544\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:49 INFO 139784435615552] Epoch[0] Validation-accuracy=0.882812\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:49 INFO 139784435615552] Storing the best model with validation accuracy: 0.882812\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:50 INFO 139784435615552] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:54 INFO 139784435615552] Epoch[1] Batch [20]#011Speed: 148.905 samples/sec#011accuracy=0.784226\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:55 INFO 139784435615552] Epoch[1] Train-accuracy=0.767940\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:55 INFO 139784435615552] Epoch[1] Time cost=5.543\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:56 INFO 139784435615552] Epoch[1] Validation-accuracy=0.923828\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:56 INFO 139784435615552] Storing the best model with validation accuracy: 0.923828\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:40:56 INFO 139784435615552] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:00 INFO 139784435615552] Epoch[2] Batch [20]#011Speed: 150.853 samples/sec#011accuracy=0.835193\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:01 INFO 139784435615552] Epoch[2] Train-accuracy=0.825521\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:01 INFO 139784435615552] Epoch[2] Time cost=5.497\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:02 INFO 139784435615552] Epoch[2] Validation-accuracy=0.973958\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:02 INFO 139784435615552] Storing the best model with validation accuracy: 0.973958\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:02 INFO 139784435615552] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:06 INFO 139784435615552] Epoch[3] Batch [20]#011Speed: 149.064 samples/sec#011accuracy=0.863839\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:08 INFO 139784435615552] Epoch[3] Train-accuracy=0.859086\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:08 INFO 139784435615552] Epoch[3] Time cost=5.552\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:08 INFO 139784435615552] Epoch[3] Validation-accuracy=0.914062\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:13 INFO 139784435615552] Epoch[4] Batch [20]#011Speed: 148.689 samples/sec#011accuracy=0.938988\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:14 INFO 139784435615552] Epoch[4] Train-accuracy=0.942419\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:14 INFO 139784435615552] Epoch[4] Time cost=5.572\u001b[0m\n",
      "\u001b[34m[03/14/2023 17:41:14 INFO 139784435615552] Epoch[4] Validation-accuracy=0.960938\u001b[0m\n",
      "\n",
      "2023-03-14 17:41:36 Uploading - Uploading generated training model\n",
      "2023-03-14 17:41:36 Completed - Training job completed\n",
      "Training seconds: 258\n",
      "Billable seconds: 258\n"
     ]
    }
   ],
   "source": [
    "image_classification_model.fit(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7eafc8-109f-47b7-9a03-ea53bf86dc06",
   "metadata": {},
   "source": [
    "We have achieved a training set accuracy of 99% and validation set accuracy of 95% which is a good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0b96e-1a5a-4716-b7ae-1d338b2eb41e",
   "metadata": {},
   "source": [
    "Now let's deploy your model on a single ml.m5.xlarge instance and also add the data capture object created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75675e0b-63d5-4584-9689-b40a2f66b1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: image-classification-2023-03-14-17-44-15-030\n",
      "INFO:sagemaker:Creating endpoint-config with name image-classification-2023-03-14-17-44-15-030\n",
      "INFO:sagemaker:Creating endpoint with name image-classification-2023-03-14-17-44-15-030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!image-classification-2023-03-14-17-44-15-030\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "\n",
    "deployment = image_classification_model.deploy(\n",
    "    initial_instance_count=1, instance_type='ml.m5.xlarge',\n",
    "    serializer=IdentitySerializer(content_type=\"application/x-image\")\n",
    "    )\n",
    "\n",
    "endpoint = deployment.endpoint_name\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89631a85-ffd2-4896-b667-47d15b1e5f12",
   "metadata": {},
   "source": [
    "The below function randomly selects an object from test folder and stores it locally in a tmp folder for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dda4d646-379f-4813-aa31-65c6d60552fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File selected  weather_classification/test/rain205.png\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "import boto3\n",
    "import random\n",
    "import os\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "objects = s3_resource.Bucket(bucket).objects.filter(Prefix=\"weather_classification/test\")\n",
    "obj = random.choice([x.key for x in objects])\n",
    "print('File selected ',obj)\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# with open(file_path, 'wb') as f:\n",
    "s3_client.download_file(bucket, obj, 'tmp/image.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceaf17c-8256-44c3-8971-18fae2570864",
   "metadata": {},
   "source": [
    "Create the predictor object for making predictions. You should pass the name of the endpoint and the session variable as parameters. IdentitySerializer helps in serializing the input for the inference endpoint and here we will specify the file type. We would have already specified the serializer in the deployment function. Both ways are acceptable.\n",
    "\n",
    "The predictor will return all class probabilites as the output. Class label for the input image corresponds to the index of the highest probability value in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3c0e1d6-5588-4926-9aaa-64c1c9ec6ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.237225846916772e-08, 0.9989890456199646, 0.00011317242024233565, 0.0265173502266407]\n"
     ]
    }
   ],
   "source": [
    "predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint,\n",
    "                                         sagemaker_session=session)\n",
    "\n",
    "predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "\n",
    "with open(\"tmp/image.png\", \"rb\") as f:\n",
    "    image = f.read()\n",
    "\n",
    "    \n",
    "result = predictor.predict(image)\n",
    "print(result.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962264d-66c2-468f-9748-36daa4316ea9",
   "metadata": {},
   "source": [
    "There is an alternate way for getting predictions and this method would be handy while deploying the model in lambda function. We can make predictions by the invoke_endpoint method of the runtime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e0e7339-b727-470d-9ba6-4f643e8ddf67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.237225846916772e-08, 0.9989890456199646, 0.00011317242024233565, 0.0265173502266407]\n"
     ]
    }
   ],
   "source": [
    "runtime= boto3.client('runtime.sagemaker')\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint,\n",
    "                                       ContentType='image/png',\n",
    "                                       Body=image)\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81b7f4f4-5e08-4d12-b403-cf73c33fa0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudy 0.0% rain 99.9% shine 0.01% sunrise 2.65% "
     ]
    }
   ],
   "source": [
    "classes = [\"cloudy\", \"rain\", \"shine\", \"sunrise\"]\n",
    "for i, val in enumerate(classes):\n",
    "    print(classes[i], round(result[i]*100,2), end=\"% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd766-8981-4b8e-b6d0-f301b79418ec",
   "metadata": {},
   "source": [
    "If you are not using the endpoint please delete it. Because if left undeleted it would keep consuming resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9a07b-9244-4d4e-949d-feebe7084efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
